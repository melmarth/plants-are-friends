{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4880a42-2091-4e8e-b753-5765f661e40a",
   "metadata": {},
   "source": [
    "# Plants are Friends Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8bd61-5190-48ae-94be-8d0d89080a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6b60c-a1ce-48b7-a47a-0132bb1397b5",
   "metadata": {},
   "source": [
    "# Gather info then consolidate\n",
    "This script produces a csv of data from the tables from houseplantsexpert.com/a-z-list-of-house-plants. <br>\n",
    "Some things to consider:\n",
    "- Different sources may have different information\n",
    "- Make dataframes from scraped websites until satisfied with level of data (chose from 5 websites)\n",
    "- Compare differences and take the most likely to be accurate (most agreement)\n",
    "- fill in gaps manually if reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ea160-2149-4fe9-bf15-49b41dcc99f5",
   "metadata": {},
   "source": [
    "## Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7102b7-a37c-41a0-b38f-8e1e68d8001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from houseplants expert\n",
    "scrap1 = requests.get('https://houseplantsexpert.com/a-z-list-of-house-plants.html')\n",
    "scrap1.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7069a37f-5758-41e9-95f6-c3f4d4bc5e39",
   "metadata": {},
   "source": [
    "### Get a list of plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4b718-b43a-43e3-bec6-34cadbe669db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plant_soup1 = BS(scrap1.text)\n",
    "plant_list1 = plant_soup1.find_all('a', {'href': re.compile(r'https://houseplantsexpert.com/shop/category/houseplants/.*')})\n",
    "plant_list1 = [x.text for x in plant_list1]\n",
    "plant_list1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69388732-bf8b-404e-9d08-0bf4e26a139e",
   "metadata": {},
   "source": [
    "### Start collecting the data\n",
    "First I want an idea of how many plants and which ones, are in this website, so this next bit is not 100% necessary but allows for an idea of the data. I did this for multiple websites in order to vet them for the project and settled on houseplantsexpert.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4db5d2-d6dc-4434-b0a4-b3a7505bae6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generates list of hrefs for individual plant pages minus all the other links on the first page\n",
    "plant_list1 = plant_soup1.find_all('a', {'href': re.compile(r'https://houseplantsexpert.com/.*')})[166:409]\n",
    "\n",
    "name_list1 = [x.text for x in plant_list1]\n",
    "href_list1 = [x['href'] for x in plant_list1]\n",
    "source1_df = pd.DataFrame({'common_name': name_list1, 'url': href_list1})\n",
    "\n",
    "# Remove the rows for which the name is empty\n",
    "source1_df = source1_df.loc[source1_df.common_name != '']\n",
    "\n",
    "# pull the fancy name into a different column and remove the duplicated rows\n",
    "source1_df['fancy_name'] = source1_df['common_name']\n",
    "source1_df['duplicate'] = False\n",
    "for i in range(0, source1_df.shape[0]-1):\n",
    "    next_row = i + 1\n",
    "    if source1_df.iloc[next_row,1] == source1_df.iloc[i,1]:\n",
    "        source1_df.iloc[i,2] = source1_df.iloc[next_row,0]\n",
    "        source1_df.iloc[next_row,3] = True\n",
    "\n",
    "source1_df['duplicate'].value_counts()\n",
    "source1_df = source1_df.loc[~source1_df.duplicate]\n",
    "source1_df = source1_df.drop(columns='duplicate')\n",
    "source1_df = source1_df.reset_index(drop=True)\n",
    "source1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45e1c38-9ae0-400c-b031-b45c107a1299",
   "metadata": {},
   "source": [
    "#### Scrape the tables from each of the individual plant pages into a dictionary\n",
    "This site has two tables that will be very useful their fields aren't always in the same order but usually they have the same name. So I'll build a dictionary. <br>\n",
    "NOTE: This step can take a while to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18507f22-c6e2-419f-be0a-42a511783c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# go get the tables from the urls\n",
    "url_list = source1_df['url'].to_list()\n",
    "dict_list = []\n",
    "err_list = []\n",
    "for u in range(0,len(url_list)):\n",
    "    scr = requests.get(url_list[u])\n",
    "    if scr.status_code == 200:\n",
    "        scr = BS(scr.text)\n",
    "        scr_list = [x.text for x in scr.find_all('td')]\n",
    "        scr_dict = {}\n",
    "        for i in range(0,len(scr_list),2):\n",
    "            k = scr_list[i].strip(':')\n",
    "            scr_dict[k] = scr_list[i+1]\n",
    "        dict_list.append(scr_dict)\n",
    "    else:\n",
    "        err_list.append(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5f0845-acb0-4d40-a053-c7e072fcd24c",
   "metadata": {},
   "source": [
    "#### Check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10636b69-3991-4028-b52f-ead9b3d2fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be a list of dictionaries\n",
    "dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961827eb-6dba-4665-a2d9-46b8d947d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be empty unless a link didn't work\n",
    "err_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbf373-fe98-4a59-9370-87239f1bed5b",
   "metadata": {},
   "source": [
    "### Convert to a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e15af7-bebc-4713-8440-dbef6e81b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "plants_df = pd.DataFrame(dict_list)\n",
    "plants_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964cebc-346d-4d19-9bbb-c793f0344666",
   "metadata": {},
   "source": [
    "### Cleanup time!\n",
    "Some of the fields have a slightly different names so they will need to be merged. At some point this website changed the format of their tables so plants before and after that point have differences. There are missing data points as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efe12b0-d241-4855-938d-8e4329f5a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plants_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36dbab-7f08-4109-85b9-0f56fe79269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the names\n",
    "plants_df['Common Name'] = plants_df['Names'].str.split(' \\(common\\).', expand=True)[0]\n",
    "plants_df['Bot_Name'] = plants_df['Names'].str.split(' \\(common\\).', expand=True)[1]\n",
    "\n",
    "# get the names for the 3 delinquents\n",
    "plants_df.iloc[52,-2] = plants_df.iloc[52,22][:15]\n",
    "plants_df.iloc[52,-1] = 'Ficus lyrata'\n",
    "plants_df.iloc[101,-2] = plants_df.iloc[101,22][:11]\n",
    "plants_df.iloc[101,-1] = 'Dracaena trifasciata'\n",
    "\n",
    "# drop the empty row at 102\n",
    "plants_df = plants_df.drop(index=102).reset_index(drop=True)\n",
    "\n",
    "# fix some soil columns\n",
    "plants_df.iloc[52,6] = plants_df.iloc[52,22] + ', ' + plants_df.iloc[52,23]\n",
    "plants_df.iloc[74,6] = plants_df.iloc[74,24]\n",
    "\n",
    "# drop unnecessary columns\n",
    "plants_df = plants_df.drop(columns = ['Pruning and grooming: ', 'Grooming and pruning', 'Names', \n",
    "                                      'Soil Type', 'Soil pH', 'Potting Soil', 'Resting Period', 'Family', \n",
    "                                      'Leaf Size', 'Flower', 'Pruning', 'Grooming And Pruning', 'Common Names', 'Botanical Name'])\n",
    "plants_df = plants_df.rename(columns = {'Bot_Name':'Botanical Name'})\n",
    "\n",
    "# result\n",
    "plants_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e5c00c-2e83-442d-89df-12d9cbff95a6",
   "metadata": {},
   "source": [
    "### Uncomment and run this to save to a csv\n",
    "See the cleanup notebook for further data cleaning processes starting from the csv below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95324d0-60c1-4961-adce-a3fe5dc9e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plants_df.to_csv('plants1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
